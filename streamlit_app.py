import streamlit as st
import numpy as np
import torch
import matplotlib.pyplot as plt
import requests
from lstm_power_regression import LSTMRegressor

# ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
class NormalizationStats:
    def __init__(self, x_mean, x_std, y_mean, y_std):
        self.X_mean = x_mean
        self.X_std = x_std
        self.y_mean = y_mean
        self.y_std = y_std

    def normalize(self, X):
        return (X - self.X_mean) / self.X_std

    def denormalize(self, y_tensor):
        return y_tensor * self.y_std + self.y_mean

def get_forecast_and_predict(model, stats, latitude=37.5665, longitude=126.9780, hours=24):
    base_url = "https://api.open-meteo.com/v1/forecast"
    params = {
        "latitude": latitude,
        "longitude": longitude,
        "hourly": "temperature_2m,cloudcover,windspeed_10m",
        "timezone": "Asia/Seoul",
    }

    response = requests.get(base_url, params=params)
    if response.status_code != 200:
        raise Exception("API ìš”ì²­ ì‹¤íŒ¨")

    data = response.json()["hourly"]
    temperature = data["temperature_2m"][:hours]
    windspeed = data["windspeed_10m"][:hours]
    cloudcover = data["cloudcover"][:hours]

    sunshine_duration = [max(0, 12 - (c / 100) * 12) for c in cloudcover]

    X_input = np.array([
        [temperature[i], windspeed[i], sunshine_duration[i]]
        for i in range(hours)
    ])

    X_input = stats.normalize(X_input)
    SEQ_LEN = 24

    if len(X_input) < SEQ_LEN:
        raise ValueError(f"ì˜ˆì¸¡ì„ ìœ„í•´ ìµœì†Œ {SEQ_LEN}ê°œì˜ ì‹œê³„ì—´ ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ë§Œ, {len(X_input)}ê°œë§Œ ìˆ˜ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.")

    sequences = np.array([X_input[i:i+SEQ_LEN] for i in range(len(X_input) - SEQ_LEN)])

    if sequences.shape[0] == 0:
        raise ValueError("ê¸°ìƒ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    X_tensor = torch.tensor(sequences, dtype=torch.float32)

    model.eval()
    with torch.no_grad():
        y_pred = model(X_tensor).squeeze().numpy()
        y_pred = stats.denormalize(torch.tensor(y_pred)).numpy()

    return y_pred

# ëª¨ë¸ ë° í†µê³„ ë¡œë“œ
model = LSTMRegressor()
model.load_state_dict(torch.load("lstm_power_model.pth", map_location=torch.device('cpu')))
model.eval()

stats_dict = torch.load("normalization_stats.pt")
stats = NormalizationStats(
    stats_dict['X_mean'],
    stats_dict['X_std'],
    stats_dict['y_mean'],
    stats_dict['y_std']
)

# Streamlit ëŒ€ì‹œë³´ë“œ êµ¬ì„±
st.set_page_config(page_title="AI ì‹ ì¬ìƒì—ë„ˆì§€ ì˜ˆì¸¡", layout="wide")
st.title("ğŸ”‹ ì‹ ì¬ìƒì—ë„ˆì§€ ë°œì „ëŸ‰ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")

st.markdown("""
ì´ ëŒ€ì‹œë³´ë“œëŠ” **Open-Meteo API**ë¡œë¶€í„° ì‹¤ì‹œê°„ ê¸°ìƒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³ ,
í•™ìŠµëœ **LSTM ëª¨ë¸**ì„ í™œìš©í•´ í–¥í›„ ë°œì „ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

- ì…ë ¥: ê¸°ì˜¨, í’ì†, êµ¬ë¦„ëŸ‰
- ì¶œë ¥: ì˜ˆì¸¡ ë°œì „ëŸ‰ (íƒœì–‘ê´‘ + í’ë ¥)
""")

if st.button("ğŸ“¡ ì‹¤ì‹œê°„ ê¸°ìƒ ì˜ˆë³´ ê¸°ë°˜ ë°œì „ëŸ‰ ì˜ˆì¸¡ ì‹œì‘"):
    try:
        predictions = get_forecast_and_predict(model, stats)
        st.subheader("ğŸ“ˆ 24ì‹œê°„ ì˜ˆì¸¡ ë°œì „ëŸ‰ (Watt)")
        st.line_chart(predictions)
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

st.markdown("""
---
**ì‚¬ìš©ëœ ëª¨ë¸:** LSTM (Long Short-Term Memory)\
**ê¸°ìƒ API:** [Open-Meteo](https://open-meteo.com/)
""")
